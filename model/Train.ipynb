{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras import *\n",
    "from keras import layers\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import *\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_df= pd.read_csv(\"trains.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>16925</td>\n",
       "      <td>Bernie Sanders Introduces Killer Mike At Coac...</td>\n",
       "      <td>On April 16th, Senator Bernie Sanders, through...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>16926</td>\n",
       "      <td>TRUMP SUPPORTERS STORM MAXINE WATERS TOWN HALL...</td>\n",
       "      <td>This is great! Trump supporters did everything...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10015</th>\n",
       "      <td>16927</td>\n",
       "      <td>Trump adds nuance to pro-Israel approach ahead...</td>\n",
       "      <td>WASHINGTON/JERUSALEM (Reuters) - During his 20...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016</th>\n",
       "      <td>16928</td>\n",
       "      <td>Top U.S. officials to testify in Trump-Russia ...</td>\n",
       "      <td>WASHINGTON (Reuters) - The U.S. House of Repre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10017</th>\n",
       "      <td>16929</td>\n",
       "      <td>Review: ‘Allied,’ With Brad Pitt and Marion Co...</td>\n",
       "      <td>“Allied,” Robert Zemeckis’s deft and diverting...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10018 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              title  \\\n",
       "0               0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1               1                                                NaN   \n",
       "2               2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3               3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4               4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "...           ...                                                ...   \n",
       "10013       16925   Bernie Sanders Introduces Killer Mike At Coac...   \n",
       "10014       16926  TRUMP SUPPORTERS STORM MAXINE WATERS TOWN HALL...   \n",
       "10015       16927  Trump adds nuance to pro-Israel approach ahead...   \n",
       "10016       16928  Top U.S. officials to testify in Trump-Russia ...   \n",
       "10017       16929  Review: ‘Allied,’ With Brad Pitt and Marion Co...   \n",
       "\n",
       "                                                    text  label  \n",
       "0      No comment is expected from Barack Obama Membe...      1  \n",
       "1         Did they post their votes for Hillary already?      1  \n",
       "2       Now, most of the demonstrators gathered last ...      1  \n",
       "3      A dozen politically active pastors came here f...      0  \n",
       "4      The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n",
       "...                                                  ...    ...  \n",
       "10013  On April 16th, Senator Bernie Sanders, through...      1  \n",
       "10014  This is great! Trump supporters did everything...      1  \n",
       "10015  WASHINGTON/JERUSALEM (Reuters) - During his 20...      0  \n",
       "10016  WASHINGTON (Reuters) - The U.S. House of Repre...      0  \n",
       "10017  “Allied,” Robert Zemeckis’s deft and diverting...      0  \n",
       "\n",
       "[10018 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10018 entries, 0 to 10017\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  10018 non-null  int64 \n",
      " 1   title       9951 non-null   object\n",
      " 2   text        10009 non-null  object\n",
      " 3   label       10018 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 313.2+ KB\n"
     ]
    }
   ],
   "source": [
    "sms_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     0\n",
       "title         67\n",
       "text           9\n",
       "label          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_df=sms_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9942 entries, 0 to 10017\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  9942 non-null   int64 \n",
      " 1   title       9942 non-null   object\n",
      " 2   text        9942 non-null   object\n",
      " 3   label       9942 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 388.4+ KB\n"
     ]
    }
   ],
   "source": [
    "sms_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-5cccea66aba9>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sms_df['label']= pd.to_numeric(sms_df['label'])\n"
     ]
    }
   ],
   "source": [
    "sms_df['label']= pd.to_numeric(sms_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = sms_df['text']\n",
    "labels = sms_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_texts, test_texts, other_labels, test_labels  = train_test_split(texts, labels, test_size=0.1, random_state=302)\n",
    "#Create validation sample\n",
    "train_texts, valid_texts, train_labels, valid_labels  = train_test_split(other_texts, other_labels, test_size=0.2, random_state=302)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABULARY_SIZE = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=VOCABULARY_SIZE)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "# Convert words into word ids\n",
    "meanLength = np.mean([len(item.split(\" \")) for item in train_texts])\n",
    "MAX_SENTENCE_LENGTH = int(meanLength + 5) # we let a text go 10 words longer than the mean text length.\n",
    "\n",
    "# Convert train, validation, and test text into lists with word ids\n",
    "trainFeatures = tokenizer.texts_to_sequences(train_texts)\n",
    "trainFeatures = pad_sequences(trainFeatures, MAX_SENTENCE_LENGTH, padding='post')\n",
    "trainLabels = train_labels.values\n",
    "\n",
    "validFeatures = tokenizer.texts_to_sequences(valid_texts)\n",
    "validFeatures = pad_sequences(validFeatures, MAX_SENTENCE_LENGTH, padding='post')\n",
    "validLabels = valid_labels.values\n",
    "\n",
    "testFeatures = tokenizer.texts_to_sequences(test_texts)\n",
    "testFeatures = pad_sequences(testFeatures, MAX_SENTENCE_LENGTH, padding='post')\n",
    "testLabels = test_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "547"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SENTENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTERS_SIZE = 16\n",
    "KERNEL_SIZE = 5\n",
    "\n",
    "# Define embeddings dimensions (columns in matrix fed into CNN and nodes in hidden layer of built-in keras function)\n",
    "EMBEDDINGS_DIM = 11\n",
    "\n",
    "# Hyperparameters for model tuning\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 547, 11)           275011    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 543, 16)           896       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 543, 16)           0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 276,052\n",
      "Trainable params: 276,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Word CNN\n",
    "model = Sequential()\n",
    "\n",
    "# We use built-in keras funtion to generate embeddings. Another option is pre-trained embeddings with Word2vec or GloVe.\n",
    "model.add(Embedding(input_dim=VOCABULARY_SIZE + 1, output_dim=EMBEDDINGS_DIM, input_length=len(trainFeatures[0])))\n",
    "model.add(Conv1D(FILTERS_SIZE, KERNEL_SIZE, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "            \n",
    "optimizer = optimizers.Adam(lr=LEARNING_RATE)\n",
    "model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "224/224 [==============================] - 4s 16ms/step - loss: 0.6504 - accuracy: 0.6120 - val_loss: 0.5433 - val_accuracy: 0.8553\n",
      "Epoch 2/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.4224 - accuracy: 0.8284 - val_loss: 0.3189 - val_accuracy: 0.8821\n",
      "Epoch 3/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.2979 - accuracy: 0.8893 - val_loss: 0.2604 - val_accuracy: 0.9106\n",
      "Epoch 4/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.2161 - accuracy: 0.9275 - val_loss: 0.2188 - val_accuracy: 0.9201\n",
      "Epoch 5/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.1596 - accuracy: 0.9440 - val_loss: 0.2010 - val_accuracy: 0.9168\n",
      "Epoch 6/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.1158 - accuracy: 0.9626 - val_loss: 0.1604 - val_accuracy: 0.9358\n",
      "Epoch 7/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.0897 - accuracy: 0.9744 - val_loss: 0.1611 - val_accuracy: 0.9369\n",
      "Epoch 8/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.0627 - accuracy: 0.9835 - val_loss: 0.1527 - val_accuracy: 0.9341\n",
      "Epoch 9/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.0497 - accuracy: 0.9871 - val_loss: 0.1451 - val_accuracy: 0.9397\n",
      "Epoch 10/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.0391 - accuracy: 0.9892 - val_loss: 0.1487 - val_accuracy: 0.9385\n",
      "Epoch 11/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.0349 - accuracy: 0.9897 - val_loss: 0.1526 - val_accuracy: 0.9363\n",
      "Epoch 12/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.0272 - accuracy: 0.9927 - val_loss: 0.1592 - val_accuracy: 0.9380\n",
      "Epoch 13/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.0278 - accuracy: 0.9925 - val_loss: 0.1695 - val_accuracy: 0.9285\n",
      "Epoch 14/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.0246 - accuracy: 0.9932 - val_loss: 0.1637 - val_accuracy: 0.9358\n",
      "Epoch 15/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.1817 - val_accuracy: 0.9291\n",
      "Epoch 16/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.1715 - val_accuracy: 0.9369\n",
      "Epoch 17/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.1708 - val_accuracy: 0.9391\n",
      "Epoch 18/18\n",
      "224/224 [==============================] - 3s 15ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.1768 - val_accuracy: 0.9391\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainFeatures, trainLabels, validation_data = (validFeatures, validLabels), batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "twt = [\"WASHINGTON/JERUSALEM (Reuters) - During his 20\"]\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(twt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "   148 1368  139  134   21  417]]\n",
      "1/1 - 0s\n",
      "[0.00733402]\n"
     ]
    }
   ],
   "source": [
    "twt = pad_sequences(twt, maxlen=720, dtype='int32', value=0)\n",
    "print(twt)\n",
    "sentiment = model.predict(twt,batch_size=20,verbose = 2)[0]\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "output_dir = re.sub('Model and data', 'Flask application', current_dir)\n",
    "os.chdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
